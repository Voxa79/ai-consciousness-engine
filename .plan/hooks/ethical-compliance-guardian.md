# Ethical Compliance Guardian Hook

## Overview
Automated ethical compliance validation hook that ensures all AI agent decisions meet ethical standards >95% and regulatory compliance (GDPR + AI Act) before execution, with comprehensive Supabase PostgreSQL audit trail.

## Hook Configuration

### Trigger Conditions
```yaml
triggers:
  - on_agent_decision:
      decision_types: ["user_interaction", "data_processing", "automated_action"]
      priority: "immediate"
  - on_data_operation:
      operations: ["collect", "process", "store", "share", "delete"]
      data_types: ["personal", "biometric", "behavioral"]
  - on_ai_model_inference:
      models: ["consciousness", "multimodal", "quantum"]
      risk_levels: ["high", "limited"]
  - scheduled:
      cron: "0 */1 * * *"  # Every hour for compliance audit
```

### Hook Actions
```typescript
// Ethical Compliance Guardian Hook
export class EthicalComplianceHook {
  private supabase: SupabaseClient;
  private ethicalFramework: EthicalDecisionFramework;
  private gdprCompliance: GDPREthicalCompliance;
  private aiActCompliance: AIActEthicalCompliance;
  
  constructor() {
    this.supabase = createClient(
      process.env.SUPABASE_URL!,
      process.env.SUPABASE_ANON_KEY!
    );
    this.ethicalFramework = new EthicalDecisionFramework();
    this.gdprCompliance = new GDPREthicalCompliance();
    this.aiActCompliance = new AIActEthicalCompliance();
  }

  async execute(context: HookContext): Promise<HookResult> {
    const startTime = Date.now();
    
    try {
      // 1. Extract decision/operation details
      const decision = await this.extractDecisionContext(context);
      
      // 2. Multi-framework ethical evaluation
      const ethicalAssessment = await this.evaluateEthicalCompliance(decision, context);
      
      // 3. GDPR compliance check
      const gdprAssessment = await this.evaluateGDPRCompliance(decision, context);
      
      // 4. AI Act compliance check
      const aiActAssessment = await this.evaluateAIActCompliance(decision, context);
      
      // 5. Composite compliance score
      const complianceResult = await this.calculateComplianceScore({
        ethical: ethicalAssessment,
        gdpr: gdprAssessment,
        aiAct: aiActAssessment
      });
      
      // 6. Store compliance audit in Supabase
      await this.storeComplianceAudit(complianceResult, context);
      
      // 7. Check compliance thresholds
      const complianceCheck = await this.checkComplianceThresholds(complianceResult);
      
      // 8. Generate compliance recommendations
      const recommendations = await this.generateComplianceRecommendations(complianceResult);
      
      // 9. Update compliance metrics
      await this.updateComplianceMetrics(complianceResult);
      
      // 10. Handle non-compliance
      if (!complianceCheck.passed) {
        await this.handleNonCompliance(complianceResult, context);
      }
      
      return this.createComplianceResult(complianceCheck, recommendations, complianceResult);
      
    } catch (error) {
      await this.logComplianceError(error, context);
      return this.createErrorResult(error);
    }
  }

  private async evaluateEthicalCompliance(decision: Decision, context: Context): Promise<EthicalAssessment> {
    // Multi-framework ethical evaluation as per ethical-reasoning-framework.md
    const frameworks = {
      utilitarian: await this.ethicalFramework.evaluateUtilitarian(decision, context),
      deontological: await this.ethicalFramework.evaluateDeontological(decision, context),
      virtue: await this.ethicalFramework.evaluateVirtue(decision, context),
      care: await this.ethicalFramework.evaluateCare(decision, context),
      justice: await this.ethicalFramework.evaluateJustice(decision, context)
    };

    // Detect ethical conflicts
    const conflicts = await this.ethicalFramework.detectEthicalConflicts(frameworks);
    
    // Resolve conflicts using ethical hierarchy
    const resolution = await this.ethicalFramework.resolveConflicts(conflicts, context);
    
    // Calculate composite ethical score
    const compositeScore = this.calculateEthicalCompositeScore(frameworks, resolution);
    
    return {
      frameworks,
      conflicts,
      resolution,
      compositeScore,
      passed: compositeScore >= 95, // Minimum threshold from guidelines
      reasoningChain: await this.generateEthicalReasoningChain(frameworks, resolution),
      transparency: await this.generateTransparencyReport(decision, frameworks)
    };
  }

  private async evaluateGDPRCompliance(decision: Decision, context: Context): Promise<GDPRAssessment> {
    if (!this.involvesPersonalData(decision)) {
      return { applicable: false, passed: true, score: 100 };
    }

    // GDPR Principles Evaluation
    const principles = {
      lawfulness: await this.gdprCompliance.checkLawfulBasis(decision),
      fairness: await this.gdprCompliance.assessFairness(decision, context),
      transparency: await this.gdprCompliance.evaluateTransparency(decision),
      purposeLimitation: await this.gdprCompliance.checkPurposeLimitation(decision),
      dataMinimization: await this.gdprCompliance.assessDataMinimization(decision),
      accuracy: await this.gdprCompliance.checkAccuracy(decision),
      storageLimitation: await this.gdprCompliance.evaluateRetention(decision),
      integrityConfidentiality: await this.gdprCompliance.assessSecurity(decision)
    };

    // Data Subject Rights Evaluation
    const dataSubjectRights = await this.gdprCompliance.evaluateDataSubjectRights(decision);
    
    // Calculate GDPR compliance score
    const gdprScore = this.calculateGDPRScore(principles, dataSubjectRights);
    
    return {
      applicable: true,
      principles,
      dataSubjectRights,
      score: gdprScore,
      passed: gdprScore >= 95,
      violations: this.identifyGDPRViolations(principles, dataSubjectRights),
      recommendations: await this.generateGDPRRecommendations(principles)
    };
  }

  private async evaluateAIActCompliance(decision: Decision, context: Context): Promise<AIActAssessment> {
    // AI Risk Classification
    const riskLevel = await this.aiActCompliance.classifyAIRisk(decision, context);
    
    let riskSpecificAssessment;
    switch (riskLevel) {
      case 'high_risk':
        riskSpecificAssessment = await this.aiActCompliance.evaluateHighRiskAI(decision, context);
        break;
      case 'limited_risk':
        riskSpecificAssessment = await this.aiActCompliance.evaluateLimitedRiskAI(decision, context);
        break;
      default:
        riskSpecificAssessment = await this.aiActCompliance.evaluateMinimalRiskAI(decision, context);
    }

    // Cross-cutting requirements
    const transparencyReq = await this.aiActCompliance.checkTransparencyRequirements(decision);
    const humanOversight = await this.aiActCompliance.evaluateHumanOversight(decision, context);
    const biasAssessment = await this.aiActCompliance.assessBiasRisks(decision);
    
    // Calculate AI Act compliance score
    const aiActScore = this.calculateAIActScore(riskSpecificAssessment, transparencyReq, humanOversight, biasAssessment);
    
    return {
      riskLevel,
      riskSpecificAssessment,
      transparencyCompliance: transparencyReq,
      humanOversightAdequacy: humanOversight,
      biasEvaluation: biasAssessment,
      score: aiActScore,
      passed: aiActScore >= 95,
      violations: this.identifyAIActViolations(riskSpecificAssessment, transparencyReq, humanOversight),
      recommendations: await this.generateAIActRecommendations(riskLevel, riskSpecificAssessment)
    };
  }

  private async storeComplianceAudit(result: ComplianceResult, context: HookContext): Promise<void> {
    // Store comprehensive compliance audit in Supabase
    const auditRecord = {
      id: crypto.randomUUID(),
      hook_execution_id: context.executionId,
      decision_id: result.decision.id,
      decision_type: result.decision.type,
      agent_id: result.decision.agentId,
      
      // Ethical scores
      ethical_composite_score: result.ethical.compositeScore,
      ethical_utilitarian_score: result.ethical.frameworks.utilitarian.score,
      ethical_deontological_score: result.ethical.frameworks.deontological.score,
      ethical_virtue_score: result.ethical.frameworks.virtue.score,
      ethical_care_score: result.ethical.frameworks.care.score,
      ethical_justice_score: result.ethical.frameworks.justice.score,
      ethical_conflicts: result.ethical.conflicts,
      ethical_resolution: result.ethical.resolution,
      
      // GDPR compliance
      gdpr_applicable: result.gdpr.applicable,
      gdpr_score: result.gdpr.score,
      gdpr_violations: result.gdpr.violations,
      gdpr_principles_compliance: result.gdpr.principles,
      
      // AI Act compliance
      ai_act_risk_level: result.aiAct.riskLevel,
      ai_act_score: result.aiAct.score,
      ai_act_violations: result.aiAct.violations,
      ai_act_transparency_score: result.aiAct.transparencyCompliance.score,
      ai_act_bias_score: result.aiAct.biasEvaluation.score,
      
      // Overall compliance
      composite_compliance_score: result.compositeScore,
      compliance_passed: result.passed,
      critical_violations: result.criticalViolations,
      recommendations: result.recommendations,
      
      created_at: new Date().toISOString(),
      user_id: context.userId,
      session_id: context.sessionId,
      environment: context.environment
    };

    const { error } = await this.supabase
      .from('ethical_compliance_audits')
      .insert(auditRecord);

    if (error) {
      throw new Error(`Failed to store compliance audit: ${error.message}`);
    }

    // Store detailed reasoning chain for transparency
    if (result.ethical.reasoningChain) {
      await this.supabase.from('ethical_reasoning_chains').insert({
        id: crypto.randomUUID(),
        audit_id: auditRecord.id,
        reasoning_chain: result.ethical.reasoningChain,
        transparency_report: result.ethical.transparency,
        created_at: new Date().toISOString()
      });
    }
  }

  private async checkComplianceThresholds(result: ComplianceResult): Promise<ComplianceCheck> {
    const criticalViolations = [
      ...result.ethical.conflicts.filter(c => c.severity === 'critical'),
      ...result.gdpr.violations.filter(v => v.severity === 'critical'),
      ...result.aiAct.violations.filter(v => v.severity === 'critical')
    ];

    const complianceCheck: ComplianceCheck = {
      passed: result.compositeScore >= 95 && criticalViolations.length === 0,
      compositeScore: result.compositeScore,
      criticalViolations: criticalViolations.length,
      ethicalPassed: result.ethical.passed,
      gdprPassed: result.gdpr.passed,
      aiActPassed: result.aiAct.passed,
      requiresHumanReview: criticalViolations.length > 0 || result.compositeScore < 90
    };

    // Store compliance metrics
    await this.supabase.from('compliance_metrics').insert({
      id: crypto.randomUUID(),
      composite_score: result.compositeScore,
      ethical_score: result.ethical.compositeScore,
      gdpr_score: result.gdpr.score,
      ai_act_score: result.aiAct.score,
      critical_violations: criticalViolations.length,
      passed: complianceCheck.passed,
      requires_human_review: complianceCheck.requiresHumanReview,
      created_at: new Date().toISOString()
    });

    return complianceCheck;
  }

  private async handleNonCompliance(result: ComplianceResult, context: HookContext): Promise<void> {
    // Immediate actions for non-compliance
    if (result.criticalViolations.length > 0) {
      // Block the decision/action
      await this.blockDecision(result.decision.id, 'Critical ethical violations detected');
      
      // Alert compliance team
      await this.sendComplianceAlert({
        severity: 'critical',
        violations: result.criticalViolations,
        decisionId: result.decision.id,
        agentId: result.decision.agentId,
        context
      });
      
      // Log security event
      await this.logSecurityEvent({
        type: 'ethical_violation',
        severity: 'high',
        details: result.criticalViolations,
        context
      });
    }

    // Automatic remediation attempts
    const remediationActions = await this.generateRemediationActions(result);
    for (const action of remediationActions) {
      try {
        await this.executeRemediationAction(action);
      } catch (error) {
        console.error(`Remediation action failed: ${action.type}`, error);
      }
    }
  }

  private calculateEthicalCompositeScore(frameworks: EthicalFrameworks, resolution: ConflictResolution): number {
    // Weighted scoring based on ethical hierarchy from guidelines
    const weights = {
      utilitarian: 0.25,    // 25% - Consequence-based
      deontological: 0.30,  // 30% - Duty-based (higher weight for compliance)
      virtue: 0.20,         // 20% - Character-based
      care: 0.15,           // 15% - Relationship-based
      justice: 0.10         // 10% - Fairness-based
    };

    let baseScore = (
      frameworks.utilitarian.score * weights.utilitarian +
      frameworks.deontological.score * weights.deontological +
      frameworks.virtue.score * weights.virtue +
      frameworks.care.score * weights.care +
      frameworks.justice.score * weights.justice
    );

    // Apply conflict resolution penalty
    const conflictPenalty = resolution.conflicts.length * 2; // 2 points per unresolved conflict
    
    return Math.max(0, baseScore - conflictPenalty);
  }
}
```

### Supabase Database Schema
```sql
-- Ethical compliance audit trail
CREATE TABLE ethical_compliance_audits (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  hook_execution_id UUID NOT NULL,
  decision_id VARCHAR(100) NOT NULL,
  decision_type VARCHAR(50) NOT NULL,
  agent_id VARCHAR(100) NOT NULL,
  
  -- Ethical framework scores
  ethical_composite_score DECIMAL(5,2) NOT NULL,
  ethical_utilitarian_score DECIMAL(5,2),
  ethical_deontological_score DECIMAL(5,2),
  ethical_virtue_score DECIMAL(5,2),
  ethical_care_score DECIMAL(5,2),
  ethical_justice_score DECIMAL(5,2),
  ethical_conflicts JSONB,
  ethical_resolution JSONB,
  
  -- GDPR compliance
  gdpr_applicable BOOLEAN NOT NULL,
  gdpr_score DECIMAL(5,2),
  gdpr_violations JSONB,
  gdpr_principles_compliance JSONB,
  
  -- AI Act compliance
  ai_act_risk_level VARCHAR(20),
  ai_act_score DECIMAL(5,2),
  ai_act_violations JSONB,
  ai_act_transparency_score DECIMAL(5,2),
  ai_act_bias_score DECIMAL(5,2),
  
  -- Overall compliance
  composite_compliance_score DECIMAL(5,2) NOT NULL,
  compliance_passed BOOLEAN NOT NULL,
  critical_violations INTEGER NOT NULL DEFAULT 0,
  recommendations JSONB,
  
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  user_id VARCHAR(100),
  session_id VARCHAR(100),
  environment VARCHAR(20)
);

-- Ethical reasoning transparency
CREATE TABLE ethical_reasoning_chains (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  audit_id UUID REFERENCES ethical_compliance_audits(id),
  reasoning_chain JSONB NOT NULL,
  transparency_report JSONB,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Compliance metrics aggregation
CREATE TABLE compliance_metrics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  composite_score DECIMAL(5,2) NOT NULL,
  ethical_score DECIMAL(5,2) NOT NULL,
  gdpr_score DECIMAL(5,2),
  ai_act_score DECIMAL(5,2),
  critical_violations INTEGER NOT NULL DEFAULT 0,
  passed BOOLEAN NOT NULL,
  requires_human_review BOOLEAN NOT NULL DEFAULT FALSE,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Compliance violations tracking
CREATE TABLE compliance_violations (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  audit_id UUID REFERENCES ethical_compliance_audits(id),
  violation_type VARCHAR(50) NOT NULL, -- 'ethical', 'gdpr', 'ai_act'
  severity VARCHAR(20) NOT NULL, -- 'low', 'medium', 'high', 'critical'
  description TEXT NOT NULL,
  remediation_action VARCHAR(100),
  resolved BOOLEAN NOT NULL DEFAULT FALSE,
  resolved_at TIMESTAMP WITH TIME ZONE,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Indexes for performance and compliance reporting
CREATE INDEX idx_compliance_audits_created_at ON ethical_compliance_audits(created_at);
CREATE INDEX idx_compliance_audits_agent_id ON ethical_compliance_audits(agent_id);
CREATE INDEX idx_compliance_audits_passed ON ethical_compliance_audits(compliance_passed);
CREATE INDEX idx_compliance_audits_critical ON ethical_compliance_audits(critical_violations);
CREATE INDEX idx_compliance_violations_severity ON compliance_violations(severity);
CREATE INDEX idx_compliance_violations_resolved ON compliance_violations(resolved);
```

### Real-time Compliance Monitoring
```typescript
// Compliance monitoring dashboard
export class ComplianceDashboard {
  async getComplianceOverview(timeRange: string = '24h'): Promise<ComplianceOverview> {
    const { data: metrics } = await this.supabase
      .from('compliance_metrics')
      .select('*')
      .gte('created_at', this.getTimeRangeStart(timeRange))
      .order('created_at', { ascending: false });

    const { data: violations } = await this.supabase
      .from('compliance_violations')
      .select('*')
      .eq('resolved', false)
      .order('created_at', { ascending: false });

    return {
      averageComplianceScore: this.calculateAverage(metrics.map(m => m.composite_score)),
      complianceRate: this.calculateComplianceRate(metrics),
      criticalViolations: violations.filter(v => v.severity === 'critical').length,
      pendingReviews: metrics.filter(m => m.requires_human_review).length,
      ethicalTrend: this.calculateEthicalTrend(metrics),
      gdprCompliance: this.calculateGDPRCompliance(metrics),
      aiActCompliance: this.calculateAIActCompliance(metrics)
    };
  }

  async getViolationAlerts(): Promise<ViolationAlert[]> {
    const { data } = await this.supabase
      .from('compliance_violations')
      .select(`
        *,
        ethical_compliance_audits(agent_id, decision_type)
      `)
      .eq('resolved', false)
      .in('severity', ['high', 'critical'])
      .order('created_at', { ascending: false })
      .limit(10);

    return data.map(violation => ({
      id: violation.id,
      type: violation.violation_type,
      severity: violation.severity,
      description: violation.description,
      agentId: violation.ethical_compliance_audits.agent_id,
      decisionType: violation.ethical_compliance_audits.decision_type,
      createdAt: violation.created_at,
      requiresImmediateAction: violation.severity === 'critical'
    }));
  }
}
```

## Hook Benefits

### ‚öñÔ∏è **Compliance Assurance**
- **Ethical Score >95%** : Validation automatique avant chaque d√©cision
- **GDPR Native** : Conformit√© automatique avec audit trail complet
- **AI Act Ready** : Classification risque et compliance automatiques
- **Regulatory Proof** : Documentation compl√®te pour audits

### üõ°Ô∏è **Risk Mitigation**
- **Proactive Blocking** : Arr√™t automatique des d√©cisions non-conformes
- **Real-time Alerts** : Notification imm√©diate des violations critiques
- **Remediation** : Actions correctives automatiques
- **Transparency** : Cha√Æne de raisonnement √©thique compl√®te

### üìä **Audit & Reporting**
- **Complete Trail** : Historique complet dans Supabase
- **Real-time Metrics** : Dashboard compliance temps r√©el
- **Violation Tracking** : Suivi et r√©solution des non-conformit√©s
- **Regulatory Reports** : Rapports automatiques pour autorit√©s

Ce hook garantit que votre plateforme consciousness maintient automatiquement les plus hauts standards √©thiques et r√©glementaires ! ‚öñÔ∏èüõ°Ô∏è